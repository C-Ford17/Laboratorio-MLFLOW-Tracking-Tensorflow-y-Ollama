{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c014faf-e46f-48ed-948d-2b7caec1f0d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Paso 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2057454b-96ab-41f5-b670-bf0a453f18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沐ｹ Dimensiones del dataset: (1055, 42)\n",
      "\n",
      "沐ｹ Columnas:\n",
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'Class']\n",
      "\n",
      "沐ｹ Primeras filas:\n",
      "      V1      V2  V3  V4  V5  V6  V7    V8  V9  V10  ...  V33  V34  V35  \\\n",
      "0  3.919  2.6909   0   0   0   0   0  31.4   2    0  ...    0    0    0   \n",
      "1  4.170  2.1144   0   0   0   0   0  30.8   1    1  ...    0    0    0   \n",
      "2  3.932  3.2512   0   0   0   0   0  26.7   2    4  ...    0    0    1   \n",
      "3  3.000  2.7098   0   0   0   0   0  20.0   0    2  ...    0    0    1   \n",
      "4  4.236  3.3944   0   0   0   0   0  29.4   2    4  ...    0    0    0   \n",
      "\n",
      "     V36    V37  V38    V39  V40  V41  Class  \n",
      "0  2.949  1.591    0  7.253    0    0      2  \n",
      "1  3.315  1.967    0  7.257    0    0      2  \n",
      "2  3.076  2.417    0  7.601    0    0      2  \n",
      "3  3.046  5.000    0  6.690    0    0      2  \n",
      "4  3.351  2.405    0  8.003    0    0      2  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "沐ｹ Valores ﾃｺnicos de la variable objetivo 'class':\n",
      "Class\n",
      "1    699\n",
      "2    356\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# qsar_preprocessing.py\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Cargar el dataset desde OpenML\n",
    "qsar = fetch_openml(name=\"qsar-biodeg\", version=1, as_frame=True)\n",
    "df = qsar.frame\n",
    "\n",
    "# Informaciﾃｳn bﾃ｡sica\n",
    "print(\"沐ｹ Dimensiones del dataset:\", df.shape)\n",
    "print(\"\\n沐ｹ Columnas:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\n沐ｹ Primeras filas:\")\n",
    "print(df.head())\n",
    "\n",
    "# Revisar la variable objetivo\n",
    "print(\"\\n沐ｹ Valores ﾃｺnicos de la variable objetivo 'class':\")\n",
    "print(df['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5bd127-4ab6-4105-a334-a5d5f5d379ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '1']\n",
      "Categories (2, object): ['1', '2']\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ddcb84-89c1-4335-95a1-98468243b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "1    699\n",
      "0    356\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Asegurar tipo numﾃｩrico y renombrar por claridad\n",
    "df['Class'] = df['Class'].astype(int)\n",
    "\n",
    "# Convertir a 0 y 1 (opcional, pero ﾃｺtil para modelos)\n",
    "df['Class'] = df['Class'].map({2: 0, 1: 1})\n",
    "\n",
    "print(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee94df99-465f-4c34-9980-fd0c42d2dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ﾃｺnicos en la columna objetivo:\n",
      "[0 1]\n",
      "\n",
      "Cantidad de valores nulos en 'Class':\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores ﾃｺnicos en la columna objetivo:\")\n",
    "print(df['Class'].unique())\n",
    "\n",
    "print(\"\\nCantidad de valores nulos en 'Class':\")\n",
    "print(df['Class'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4c60a0-082d-44cd-960a-a8acdd393c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "沐ｹ Tamaﾃｱos:\n",
      "Entrenamiento: (844, 41)  | Prueba: (211, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n沐ｹ Tamaﾃｱos:\")\n",
    "print(\"Entrenamiento:\", X_train.shape, \" | Prueba:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6fba20c-e982-43e3-8d07-7f81778468fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f2ae7-1dcf-40b1-a5e2-6f0645268ef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Paso 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a149a3-abf0-41ed-9ff4-9064643388a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn  # Para modelos de Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4010ed-5d50-4770-989c-ce3dee477233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Christian/Documents/mlflow%202/mlruns/468532580829688563', creation_time=1760587998401, experiment_id='468532580829688563', last_update_time=1760587998401, lifecycle_stage='active', name='QSAR_Biodegradation_LogisticRegression', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre de tu experimento\n",
    "experiment_name = \"QSAR_Biodegradation_LogisticRegression\"\n",
    "\n",
    "# Crear o seleccionar el experimento\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01123c83-18cf-46df-9374-e46a473c6375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run iniciado. Ahora se pueden registrar parﾃ｡metros y mﾃｩtricas.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Aquﾃｭ dentro irﾃｭa el entrenamiento de tu modelo\n",
    "    mlflow.log_param(\"modelo\", \"Regresion Logistica\")\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    \n",
    "    # Ejemplo: despuﾃｩs de entrenar el modelo\n",
    "    # mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    print(\"Run iniciado. Ahora se pueden registrar parﾃ｡metros y mﾃｩtricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c2c89-eb3e-4a10-85fb-9edbc0f1088e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Paso 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3544d31-500c-4a28-9768-8e5864714405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:35:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/15 23:35:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Run completado. Mﾃｩtricas registradas en MLflow\n"
     ]
    }
   ],
   "source": [
    "# 沐ｹ Importar librerﾃｭas necesarias\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# 沐ｹ Configurar experimento\n",
    "mlflow.set_experiment(\"QSAR_Biodegradation_LogisticRegression\")\n",
    "\n",
    "# 沐ｹ Iniciar un run en MLflow\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Manual\"):\n",
    "\n",
    "    # Registrar parﾃ｡metros que vas a probar\n",
    "    C = 1.0\n",
    "    max_iter = 200\n",
    "    solver = 'liblinear'  # bueno para datasets pequeﾃｱos y clasificaciﾃｳn binaria\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"solver\", solver)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model = LogisticRegression(C=C, max_iter=max_iter, solver=solver)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predecir en el set de prueba\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calcular mﾃｩtricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Registrar mﾃｩtricas en MLflow\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Registrar tags\n",
    "    mlflow.set_tags({\n",
    "        \"framework\": \"scikit-learn\",\n",
    "        \"modelo\": \"Regresion Logistica\",\n",
    "        \"proposito\": \"Clasificaciﾃｳn binaria QSAR Biodegradation\"\n",
    "    })\n",
    "\n",
    "    # Crear y guardar grﾃ｡fico de matriz de confusiﾃｳn\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\n",
    "    plt.title(\"Matriz de Confusiﾃｳn\")\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Registrar artefactos (grﾃ｡fico)\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "    # Registrar descripciﾃｳn en texto\n",
    "    mlflow.log_text(\"Modelo entrenado con LogisticRegression de Scikit-learn sobre QSAR Biodegradation\", \"descripcion.txt\")\n",
    "\n",
    "    # Registrar modelo\n",
    "    mlflow.sklearn.log_model(model, \"modelo_logistico\")\n",
    "\n",
    "    print(\"笨 Run completado. Mﾃｩtricas registradas en MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced0cf0-be36-4399-b18f-e297b90b3ea4",
   "metadata": {},
   "source": [
    "## Paso 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2298f073-e818-4623-a838-adf6575b2de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Documents\\mlflow 2\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/10/15 23:35:20 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4947 - loss: 0.7238 - precision: 0.6511 - recall: 0.5417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6374 - loss: 0.6324 - precision: 0.7037 - recall: 0.7818 - val_accuracy: 0.7299 - val_loss: 0.5145 - val_precision: 0.7293 - val_recall: 0.9429\n",
      "Epoch 2/20\n",
      "\u001b[1m20/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4861 - precision: 0.7855 - recall: 0.9351 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8021 - loss: 0.4561 - precision: 0.8121 - recall: 0.9123 - val_accuracy: 0.8199 - val_loss: 0.4489 - val_precision: 0.8592 - val_recall: 0.8714\n",
      "Epoch 3/20\n",
      "\u001b[1m21/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏≫煤笏≫煤笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.4230 - precision: 0.8595 - recall: 0.8461 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8294 - loss: 0.3964 - precision: 0.8766 - recall: 0.8640 - val_accuracy: 0.8294 - val_loss: 0.4172 - val_precision: 0.8714 - val_recall: 0.8714\n",
      "Epoch 4/20\n",
      "\u001b[1m22/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3482 - precision: 0.8681 - recall: 0.8969 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8472 - loss: 0.3597 - precision: 0.8785 - recall: 0.8927 - val_accuracy: 0.8341 - val_loss: 0.3964 - val_precision: 0.8723 - val_recall: 0.8786\n",
      "Epoch 5/20\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3356 - precision: 0.8814 - recall: 0.8990 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8531 - loss: 0.3397 - precision: 0.8809 - recall: 0.8998 - val_accuracy: 0.8436 - val_loss: 0.3925 - val_precision: 0.8741 - val_recall: 0.8929\n",
      "Epoch 6/20\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.3264 - precision: 0.8927 - recall: 0.9214  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8780 - loss: 0.3269 - precision: 0.9057 - recall: 0.9106 - val_accuracy: 0.8531 - val_loss: 0.3858 - val_precision: 0.8759 - val_recall: 0.9071\n",
      "Epoch 7/20\n",
      "\u001b[1m24/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏≫煤笏―u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2717 - precision: 0.9208 - recall: 0.9391 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8780 - loss: 0.3098 - precision: 0.8958 - recall: 0.9231 - val_accuracy: 0.8483 - val_loss: 0.3854 - val_precision: 0.8699 - val_recall: 0.9071\n",
      "Epoch 8/20\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3020 - precision: 0.8859 - recall: 0.9162 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8780 - loss: 0.2972 - precision: 0.9043 - recall: 0.9123 - val_accuracy: 0.8389 - val_loss: 0.3824 - val_precision: 0.8581 - val_recall: 0.9071\n",
      "Epoch 9/20\n",
      "\u001b[1m24/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏≫煤笏―u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2817 - precision: 0.9156 - recall: 0.9136 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8803 - loss: 0.2866 - precision: 0.9046 - recall: 0.9159 - val_accuracy: 0.8389 - val_loss: 0.3737 - val_precision: 0.8533 - val_recall: 0.9143\n",
      "Epoch 10/20\n",
      "\u001b[1m25/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2991 - precision: 0.8911 - recall: 0.9367 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8981 - loss: 0.2756 - precision: 0.9186 - recall: 0.9284 - val_accuracy: 0.8483 - val_loss: 0.3691 - val_precision: 0.8600 - val_recall: 0.9214\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8886 - loss: 0.2797 - precision: 0.9029 - recall: 0.9320 - val_accuracy: 0.8436 - val_loss: 0.3781 - val_precision: 0.8591 - val_recall: 0.9143\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8803 - loss: 0.2734 - precision: 0.9046 - recall: 0.9159 - val_accuracy: 0.8483 - val_loss: 0.3748 - val_precision: 0.8553 - val_recall: 0.9286\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8922 - loss: 0.2682 - precision: 0.9091 - recall: 0.9302 - val_accuracy: 0.8483 - val_loss: 0.3750 - val_precision: 0.8600 - val_recall: 0.9214\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9028 - loss: 0.2573 - precision: 0.9206 - recall: 0.9338 - val_accuracy: 0.8436 - val_loss: 0.3770 - val_precision: 0.8543 - val_recall: 0.9214\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.2568 - precision: 0.9120 - recall: 0.9267 - val_accuracy: 0.8436 - val_loss: 0.3823 - val_precision: 0.8591 - val_recall: 0.9143\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9052 - loss: 0.2509 - precision: 0.9165 - recall: 0.9428 - val_accuracy: 0.8436 - val_loss: 0.3873 - val_precision: 0.8639 - val_recall: 0.9071\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 0.2463 - precision: 0.9175 - recall: 0.9356 - val_accuracy: 0.8531 - val_loss: 0.3734 - val_precision: 0.8658 - val_recall: 0.9214\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8981 - loss: 0.2514 - precision: 0.9057 - recall: 0.9445 - val_accuracy: 0.8626 - val_loss: 0.3771 - val_precision: 0.8725 - val_recall: 0.9286\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9040 - loss: 0.2349 - precision: 0.9299 - recall: 0.9249 - val_accuracy: 0.8531 - val_loss: 0.3801 - val_precision: 0.8658 - val_recall: 0.9214\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8969 - loss: 0.2327 - precision: 0.9155 - recall: 0.9302 - val_accuracy: 0.8626 - val_loss: 0.3804 - val_precision: 0.8725 - val_recall: 0.9286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:35:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Entrenamiento completado. Revisa la UI de MLflow para mﾃｩtricas y artefactos.\n"
     ]
    }
   ],
   "source": [
    "# 沐ｹ Importar librerﾃｭas\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# 沐ｹ Activar autologging de TensorFlow/Keras\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "# 沐ｹ Definir experimento\n",
    "mlflow.set_experiment(\"QSAR_Biodegradation_TensorFlowNN\")\n",
    "\n",
    "# 沐ｹ Crear el modelo secuencial\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # salida binaria\n",
    "])\n",
    "\n",
    "# 沐ｹ Compilar modelo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# 沐ｹ Entrenamiento dentro de MLflow\n",
    "with mlflow.start_run(run_name=\"RedNeuronal_TF\"):\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"笨 Entrenamiento completado. Revisa la UI de MLflow para mﾃｩtricas y artefactos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece2601-8fb4-4b45-aaf8-ad49322de7a6",
   "metadata": {},
   "source": [
    "## Paso 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdebbf82-b9db-4f7c-a75f-1d1684f4b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             run_id  metrics.accuracy  metrics.precision  \\\n",
      "0  70a62eb889f949f3a8f1328d2c922e41          0.853081           0.881119   \n",
      "1  50047884af344c29a957b209258f84a6          0.853081           0.881119   \n",
      "2  c42de85b144e436bbd8d86afb3fb11a5          0.853081           0.881119   \n",
      "3  238e73c2f7a44764be5b4f833a1c85cc          0.853081           0.881119   \n",
      "4  f1cadd21cd64416da2beef109ec381f3               NaN                NaN   \n",
      "5  228a1bf0db754bb982f4fb9f0fb1da88               NaN                NaN   \n",
      "6  35f6efabb92d42328133ae719fca61b3               NaN                NaN   \n",
      "7  4d110f7ab22a4398ae96bad0d99c38c4               NaN                NaN   \n",
      "\n",
      "   metrics.recall  metrics.f1_score params.C params.max_iter params.solver  \n",
      "0             0.9          0.890459      1.0             200     liblinear  \n",
      "1             0.9          0.890459      1.0             200     liblinear  \n",
      "2             0.9          0.890459      1.0             200     liblinear  \n",
      "3             0.9          0.890459      1.0             200     liblinear  \n",
      "4             NaN               NaN     None            None          None  \n",
      "5             NaN               NaN     None            None          None  \n",
      "6             NaN               NaN     None            None          None  \n",
      "7             NaN               NaN     None            None          None  \n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Seleccionar el experimento por nombre\n",
    "experiment = mlflow.get_experiment_by_name(\"QSAR_Biodegradation_LogisticRegression\")\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Buscar todos los runs\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"\",  # Puedes filtrar por tags o nombre: e.g. \"tags.modelo = 'Regresion Logistica'\"\n",
    "    order_by=[\"metrics.accuracy DESC\"]  # Ordenar por accuracy descendente\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas con mﾃｩtricas y parﾃ｡metros\n",
    "print(runs[['run_id', 'metrics.accuracy', 'metrics.precision', 'metrics.recall', 'metrics.f1_score', 'params.C', 'params.max_iter', 'params.solver']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b73efd-132e-40f8-891e-0bcfc47ea940",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.to_csv(\"comparacion_runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a96db-9aeb-4457-ada7-cb88b836dc8f",
   "metadata": {},
   "source": [
    "## Paso 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85ace73-25da-42b5-9ab1-c1b8630dc238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:40:17 INFO mlflow.tracking.fluent: Experiment with name 'QSAR_Biodegradation_Interpretacion' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Respuestas de Ollama registradas en MLflow\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Configurar el cliente Ollama local\n",
    "client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "# Modelo que descargaste\n",
    "modelo = \"llama3\"\n",
    "\n",
    "# Lista de preguntas sobre los modelos\n",
    "preguntas = [\n",
    "    \"ﾂｿQuﾃｩ significa obtener un F1-score de 0.88?\",\n",
    "    \"ﾂｿPor quﾃｩ una red neuronal podrﾃｭa tener mejor recall que una regresiﾃｳn logﾃｭstica?\",\n",
    "    \"ﾂｿQuﾃｩ podrﾃｭa mejorar el rendimiento de los modelos en este dataset?\"\n",
    "]\n",
    "\n",
    "respuestas = []\n",
    "\n",
    "for p in preguntas:\n",
    "    response = client.chat.completions.create(\n",
    "        model=modelo,\n",
    "        messages=[{\"role\": \"user\", \"content\": p}]\n",
    "    )\n",
    "    r = response.choices[0].message.content.strip()\n",
    "    respuestas.append(f\"Pregunta: {p}\\nRespuesta: {r}\\n\")\n",
    "\n",
    "# Guardar en archivo\n",
    "archivo = \"interpretacion_ollama.txt\"\n",
    "with open(archivo, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(respuestas)\n",
    "\n",
    "# Registrar en MLflow\n",
    "mlflow.set_experiment(\"QSAR_Biodegradation_Interpretacion\")\n",
    "with mlflow.start_run(run_name=\"Interpretacion_Ollama_Notebook\"):\n",
    "    mlflow.log_artifact(archivo)\n",
    "    print(\"笨 Respuestas de Ollama registradas en MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93319987-7968-4fa5-bb82-8988f4b52eec",
   "metadata": {},
   "source": [
    "## Paso 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2de598-0545-474d-a9bc-779bf685c10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:41:07 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/10/15 23:41:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for openai.\n",
      "2025/10/15 23:41:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# Activar autologging global\n",
    "mlflow.autolog()\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.tensorflow.autolog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a598b1-e27d-4562-8401-825959ec9bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:42:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/10/15 23:42:27 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/15 23:42:30 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.8577\n",
      "Fold 3 Accuracy: 0.8683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_CV\") as parent_run:\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled)):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]  # <- CORRECTO\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"Fold_{fold+1}\", nested=True):\n",
    "            model = LogisticRegression(C=1.0, max_iter=200, solver='liblinear')\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            acc = model.score(X_val_fold, y_val_fold)\n",
    "            mlflow.log_metric(\"accuracy\", acc)\n",
    "            print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9ee0d-40d5-48a8-8963-d140edefd991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLflow (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
